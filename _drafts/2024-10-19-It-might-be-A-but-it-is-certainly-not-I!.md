---
catergory: trash
layout: default
title: It might be A but it is certainly not I!
---

# It might be A but it is certainly not I!

Certainly one of the biggest debacles of the mid-2020s is the hype surrounding what is aggressively being marketed and pushed as AI.

There are two facts that must immediately be made clear. Yes, this is a hit piece *aginst* AI. I do not like the way it is being marketed. Yes, I have used ChatGPT to perform various useful technical tasks, because it can help me with certain problems.

There's a few common talking points used by the part of the general populace who are more affine to, or simply and naively want to present a talking point for, AI.

1. But human artists learn from other artists and 'copy' their work too!

Human beings are physically and mentally incapable of collecting, reading and generalizing the contents of the entire internet, and being able to reproduce it in a grammatically perfect and consistent style. Humans make mistakes, and even if one were to _attempt_ to make an exact copy of someone's art or style, it would be possible, if not easy, to make out differences arising due to imperfections. To err is human! While it is true that art students, when taken as an example, are exposed to the work of famous artists, it is much more than exposure to prior art that created people like Dali, Picasso and Van Gogh. They were _human_ - they had an upbringing that shaped them and their emotions, they interacted with the people around them, which led to a mutual exchange of feelings and ideas, and they lived in the unique locations which inspired them. AI does not have a 'life' and an 'upbringing' - it is an algorithm that exists purely inside a machine. It can be programmed to emulate any of the above, but it is exactly that - programmed.

2. If you don't want your art to be used to train AI, don't post it on the internet!

I've actually had this said to straight to my face.

What is the internet for? A non-consensual farming ground for the creation of content by computer algorithms? A place for the interchange of information and experiences, in the form of text, pictures, audio or video? A place to exchange ideas and further science? Do you have to specifically have the intention of wanting your material scraped by an AI corporation to be able to post anything on the internet?

3. But AI is so good! It will replace a lot of jobs!

AI is only good because the content it scraped (which were created by people just like you and me, and some very smart ones) is good.

I had the particular displeasure of coming across YouTube user '@firexgodx980' who was feverishly defending AI under a 3Blue1Brown short video[^].

> That's a gross oversimplification. LLMs are also Turing complete, just like humans. For all we know, humans are "just" next word predictors too.

There is a common theme, of either reducing the value of a human being by equating him to a computer algorithm that is spreading on the internet, or the opposite, giving the computer algorithm more credit than it actually deserves. This is demonstrated by another reply from the same user.

> It's a gross simplification. Imagine calling human consciousness "just electrical signals". For all we know humans are "just" next word predictors as well. LLMs do predict next words, but they are also thinking and reasoning and planning while doing so.

A human being might draw upon years of experience, without being limited by the recentness or breadth of his 'training data', and draw inspiration from completely unrelated fields and sources. An AI, on the other hand, has at it's disposal what is basically a large probability table. It can only suggest the technically 'correct' (as in, most probable) next word, and that word itself is dependent on the training data. If the training data suggests that the word 'deception' had the highest occurence in similar sentences, the AI will gladly add 'deception' to the sentence it was formulating, with no self-awareness. Once again - if the AI is 'correct', it is only because some source(s) in the training data (were) correct too. Humans do not have the memory to remember exact facts to verify the correctness of a statement, but can infer based on context and experience.

A fundamental marketing concept is to sell something as more than what it really is, and 'AI' is no different. That marketing has, unfortunately, proven to be extremely effective, extracting billions in funding from various sources. It is quite unfortunate that tech investors rarely understand what they are funding, and let themselves be talked into schemes that are unfeasible or unethical, with the promise of multiplying their investment. Claiming that a computer algorithm was invented that is capable of *thinking*, and maybe *outperforming* a human, is just such a scheme. An LLM is simply a probabilistic text generator. Nothing more, nothing less, despite what some people desperately want to *believe*.

The basis of an LLM is training data, using which it's internal probability engine (a term I made up right now) can be fine tuned. The data, in this case, is apparently the entireity of the Internet. With no warning, with no permission, the entire Internet was suddenly scraped to train a large language model. This is a copyright grey area. No laws exist that can hold the LLM culpable for copyright violation, since it does not 'traditionally' copy content. However, years of painstaking work in all fields was used to train a next-word predictor for free, which can indeed, to a large degree of accuracy, predict the next word in any context. Completely non-consensual, and LLMs have been used for commerical purposes, i.e. earning money. Years of pure human *effort*, which cannot be objectively or legally quantified, has been used, with no consent, to train an algorithm that reduces the value of effort to nothing. This is not a technical, economical or moral argument, simply a philosophical one. It has been observed many times in the past, that it is usually technical or economic forces that unfortunately shape society, and not moral or philosophical ones.

> I'd rather laugh with the sinners than cry with the saints
> The sinners are much more fun[^]

Sam Altman is a prepper. He wants to make sure him and everything that is *his* survives a possible human extinction event. He is the founder of a company that has created a product, which, in science fiction, has caused, or willed, a human extinction event. 1 + 1 = 2. He *does not care* about the 'rest' of us. We are a market to be exploited.

There are two clear examples, from my personal use of LLMs, that clearly indicate that the algorithm has no 'thinking' capability of it's own. 

GitHub Copilot has been silently and intrusively suggesting, and occasionally completing, code for me. It is quite good at the job. It can understand context, and almost always correctly completes a line of code that I started typing out. At one point, while working on a long, complex project (does the word multislope ADC mean anything to anyone), I decided to create a project log, that I put in the project folder and edited using VSCode. Copilot desperately wanted to work it's magic here too... or at least try. After generating a sentence or two of meaningful text, it started repeating itself... endlessly. It was amusing to so closely observe the limitations of a text generating algorithm, however good it was. It was simply not *writing* like a human would, but generating the most probable next sentence based on the previous sentences.

Another time, I wanted to come up with a name for a new (later, we found research papers describing it) ADC topology. To amuse myself, I decided to ask ChatGPT. The LLM decided to simply mash together the names of existing topologies in different combinations. Nothing new, no borrowing terms from other unrelated fields. Just a computer algorithm trying it's hardest to generate the most probable next word.

One can't help but appreciate and be thankful for the sheer amount of infomration posted on the Internet, all of which was tirelessly scraped by an LLM and rephrased into remarkably good sentences. It greatly emphasizes the fact that if you have a problem, someone else has already posted about it on the internet and probably already gotten an answer, which the LLM regurgitates (with additions from other such sources) into the chatbox.

## Reality Strikes Hard

After a rather long phone call with my mother about my future plans after finishing my degree, I sat down to complete a few C (the programming language) pop-quizzes that I'd been putting off for two weeks. It was required that I pass at least a certain number, in order to be allowed to write the C exam at the end of the semester.

The quizzes had a deadline, so I was under pressure to finish them quickly. The questions themselves, the way I saw it after a tiring phone call, were rather frustrating and dug into the theoretical depths of the language. Variable names were non-descriptive, but exactly as one would expect in a classroom setting - a, b, x, y and the likes. Functions were arbitrary and needed a thorough going-through before I could arrive at the expected answer. I was not in a mental state to do that.

I had been discussing the feelings I had been having lately. My high school years are still sharp in memory, and I'd already spent two years in Germany, dropped out once after a year, and started the degree once again. It felt like I'd been a student forever. It's not like I cannot do an EE job, and it's not like *Everything* taught in a university setting is useful in real life. I'd been programming rather complex microcontroller-based projects in C for a few years now. In fact, I'd brought that up during the introduction round in the first lecture. "You must know a lot, then!" said the Professor. "Maybe, but that does not mean I can skip classes, it always helps to brush up on the basics." I replied. While true, in my present state of frustration, it seemed like nothing more than an empty platitude.

Faced with the bleak prospect of years of academic drudgery and maybe not being able to finish, and getting kicked out of the degree and by extension the country, I turned to ChatGPT.

All I had to do was copy the question text and paste it into the chatbox, and the large language model wasted no time generating answers. I wasted no time or energy reading the explanation it very kindly provided, despite not being asked for, and quickly copied the answers.

I was perfectly aware of what I was doing, and willing to take responsibility. The whole purpose of this pop-quiz was to give me a chance to rework inside my head how a C program ran, and practice for the exam at the same time. By cheating, I was not learning anything and probably lessening my chances of passing the exam.

Some questions I did do myself, during which I realized I had misunderstood how the '>' and '<' operators worked. Of course, doing the exercises yourself does bring up such cases, and correcting them is highly beneficial. By letting an LLM do the work for me, I was forfeiting the learning process.

If the LLM didn't exist, would I have to do everything myself and actually learn from my mistakes? Yes. Does getting the LLM to generate answers for me act like a topical painkiller in this state of mind? Yes. I have decided to use it, which means that I should also accept the consequences of using it.

Overall, I must have spent more time agonizing about the ethical dilemma of using the LLM to provide short term comfort at the expense of long-term learning, than the pop-quiz(zes) and phone call put together.

## What Now?

As much as I hate having LLMs called even a tool (and certainly 'AI'!), given my personal experiences with it, I am forced to agree. It is a tool, whose utility is decided by the end user. A useless tool, like a rubber spanner, or perhaps something more interesting, like a Swiss army knife - a true jack-of-all-trades, something that can get you out of a pinch but has not put traditional screwdriver, corkscrew, pocket knife, toothpick or tweezer manufacturers out of business. I hate AI. I hate how it 'generates' art, and I hate how that art is being used to spite actual, talented human beings. I hate the fact that it supports exploitative capitalism. I hate that it has the potential to kill creative jobs, ironically based off of previous creative people's work, scraped without consent and digested by a computer algorithm. Looking around me, it looks like 'AI', at least in the form of exploitative LLMs will stick around for a while. God, I wish I didn't have to live through this period.

[^]: (https://www.youtube.com/shorts/KHEtJUlpqcg)[https://www.youtube.com/shorts/KHEtJUlpqcg]{:target="_blank"}
[^]: (https://www.youtube.com/watch?v=Crif5E67ar0)[https://www.youtube.com/watch?v=Crif5E67ar0]{:target="_blank"}

